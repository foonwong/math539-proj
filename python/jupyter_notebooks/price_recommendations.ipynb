{"cells":[{"source":"# Change directory to VSCode workspace root so that relative path loads work correctly. Turn this addition off with the DataScience.changeDirOnImportExport setting\nimport os\ntry:\n\tos.chdir(os.path.join(os.getcwd(), '../..'))\n\tprint(os.getcwd())\nexcept:\n\tpass\n","cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["from itertools import product\n","import pandas as pd\n","import numpy as np\n","import sys\n","sys.path.append('python')\n","from wifipricing.modeling_prepartions import get_lgb_data\n","from sklearn.externals import joblib\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["def get_price_grid(price_list, datacap_list):\n","    \"\"\"returns dataframe price and datacap list combinations\"\"\"\n","    prod = product(price_list, datacap_list)\n","    p, d = zip(*prod)  #list of tuples to two tuples\n","    return pd.DataFrame({'price_usd':p, 'datacap_mb':d})\n","\n","\n","def label_encode_mapper(df, encoder_dict):\n","    '''Label transform a training dataframe with a dict of sklearn label encoder'''\n","    for col, encoder in encoder_dict.items():\n","        df[col] = encoder.transform(df[col])\n","    return None\n","\n","\n","def label_encode_invmapper(df, encoder_dict):\n","    '''Label inv_transform a training dataframe with a dict of sklearn label encoder'''\n","    for col, encoder in encoder_dict.items():\n","        df[col] = encoder.inverse_transform(df[col])\n","    return None\n","\n","\n","def newdata_transform(data, col_order, df_transformer, encoder_dict):\n","    newdata = data.copy()\n","    df_transformer(newdata, encoder_dict) \n","\n","    return newdata[col_order]\n","\n","\n","def prep_grids(fgrid, pgrid):\n","    fgrid.drop(columns=pgrid.columns, inplace=True)\n","    fgrid['dummy'] = 1\n","    pgrid['dummy'] = 1\n","\n","    return None\n","\n","\n","def get_quantile_predictions(fit_dict, X_new):\n","    pred = {}\n","    for type, fit_obj in fit_dict.items():\n","        key = f'y_{type}'\n","        pred.update({key: fit_obj['model'].predict(X_new)})\n","    \n","    return pd.DataFrame(pred)\n","\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" Price grid settings"],"metadata":{}},{"source":["PRICES = list(range(51))\n","DATACAPS = list(np.arange(0, 160, 10)) \n","\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["# Loading model fit objects + grids"],"metadata":{}},{"source":["alljoblibs = os.listdir('models')\n","print(alljoblibs)\n","\n","subset = {'datacap':{}, 'timecap':{},'fulldata':{}}\n","\n","print('loading files double loop:') \n","for sub in subset:\n","    joblibs = [file for file in alljoblibs if sub in file]\n","\n","    for quantile in ['upper', 'median', 'lower']:\n","        path = [f'models/{x}' for x in joblibs if quantile in x][0]\n","        loaded = joblib.load(path)\n","        subset[sub].update({quantile: loaded})\n","\n","        print(f'Loaded {sub}-{quantile} --- RMSE: {loaded[\"RMSE\"]:.4f}')\n","\n","datacap_fits = subset['datacap']\n","datacap_fits['median'].keys()\n","\n","\n","\n","grid_paths = {\n","    'datacap':'data/summarized_data/df_summarized_datacap_featgrid.feather',\n","    # 'timecap':'data/summarized_data/df_summarized_timecap_featgrid.feather',\n","    # 'fulldata':'data/summarized_data/df_summarized_all_featgrid.feather'\n","}\n","\n","# for subset, path in grid_paths.items():\n","#     df = pd.read_feather(path)\n","\n","featgrid = pd.read_feather(grid_paths['datacap'])\n","price_grid = get_price_grid(PRICES, DATACAPS)\n","\n","prep_grids(featgrid, price_grid)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["featgrid.head()"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["price_grid.head()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["## Original training data shape reference:\n"," We need to make sure that our generated data has the same dtype and order"],"metadata":{}},{"source":["datacap_fits['median']['X_sample'].head()\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["# Iterate over grids"],"metadata":{}},{"source":["%timeit\n","price_grid.head()\n","pgrid = price_grid.head(5)\n","model_col_order = datacap_fits['median']['X_sample'].columns\n","\n","for i, df_row in featgrid.groupby(level=0):\n","    row_pricegrid = pd.merge(df_row, price_grid, on='dummy').drop(columns=['dummy'])\n","    X_new = newdata_transform(row_pricegrid, model_col_order, label_encode_mapper, encoder_dict)\n","\n","    predictions = get_quantile_predictions(datacap_fits, X_new)\n","    print(f\"\\nRow {i}:\")\n","    \n","    out = pd.concat([X_new, predictions], axis=1)\n","    print(out)\n","\n","    if i > 5:\n","        break\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}